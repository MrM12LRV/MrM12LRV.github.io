
<h1> Python Automatic Loop Parallelization </h1>
<h2> Joey Fernau                           </h2>

<h1> Summary </h1>
  I'm going to implement dependence testing for Python by utilzing the functionality provided by Cython, a typed superset of Python that compiles to C, in order to perform automatic loop parallelization.  The parallel systems include C vector instrinsics (available from Cython's native C calls) and/or OpenMP; the testing will be run on CPUs and/or GPUs.

<h1> Background </h1>

  <p> Python is known to suffer from performance issues; <a href="http://cython.org/"> Cython </a> is an optimizing static compiler for both Python and Cython. This project will be able to take any valid Python program, analyze its abstract syntax tree using the <a href="https://docs.python.org/2/library/ast.html"> ast module </a> by performing <a href="https://en.wikipedia.org/wiki/Loop_dependence_analysis"> Array Dependence Analysis </a> in order to determine if a loop can be parallelized.  Cython can be converted into LLVM's IR (because it compiles to C), so we can also perform analysis on this representation if Python's ast library does not prove to be sufficient for this project.  The main reason for using the Cython compiler (as opposed to the Python's original implementation: CPython) is so that once we determine if a loop can be parallelized, we can source-code-annotate the input Python program with Cython C vector instrinics and other parallizing techniques such as OpenMP.
  </p>

  <p> The process of determining this type of dependence is called dependence testing.  There are many types of dependence testers, such as Lamport's Test, the GCD test, Banerjee's Inequalities, the Power Test, the I-Test, the Omega Test, the Delta Test, the Stanford Test, and so on.  Some are less computationally expensive, but are more conservative approximations and thus may not be able to detect independence of all parallelizable loops. </p>

  <p> Cython always one to add static typing to a Python program, but this project's inputs are valid Python programs.  Even though adding this static typing will speed up the program on its own, the input program will no longer be a valid Python program.  It will be a valid Cython program.  Our inputs are only valid Python programs.  This project will source-code-annotate a Python program, effectively converting it to a Cython program, compile it with Cython, and output a library binary.

<h1> Challenge </h1>
  <p> This problem is challenging because of the nature of the problem -- automatically inferring if a loop has independent iterations reduces down to solving an integer linear program, which is NP-hard.  Thus, we must make conservative estimates.  It will be very cool to do program analysis with the end result of automatic parallelization.  This is a neat field to study, and mythical automatic parallizing compiler is one beast researchers are hunting for. </p>

  <p> I interesting to see how well the different dependence testers fair with respect to determining if a loop is parallelizable.  To make my implementation more practical and efficient, maybe a combination of the brute force ILP solver in combination with a conservative dependence tester would be the best method depending on how complex a given loop grouping is. Also, learning new optimization techniques for a compiler is fun. </p>

  <p> The workload of this project is any given Python program.  Some programs are more difficult to analyze than others.  For example, a quadruply nested for loop with hundreds of iterations per loop would be a difficult integer linear program to solve.  Thus, the conservative estimates may not be able to determine that the loop is parallelizable. </p>

<h1> Resources </h1>

  <p> I will be using Python 2.7, Cython, Python's ast library, LLVM (possibly), C/C++.  Other than that, I will be starting from scratch.  The machines I will be using will be the GHC machines since they have enough cores for worthwhile test results.  I may potentially benefit from a machine with more cores to have neater results, but I do not find that completely necessary at the moment. </p>

  <p> To learn about Array Dependence Analysis am using the Purple Dragon Book: <br/>
  Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman.
  Compilers: Principles, Techniques, and Tools (2nd Edition).
  Pearson Addison Wesley, 2006. ISBN: 978-0321486814.
  </p>

  <p> I may use other sources in order to implement the other conservative dependence testers, but I am not sure what those are yet. </p>


<h1> Goals and Deliverables </h1>

  <h3> Plan to Achieve </h3>

  I plan to achieve a project that will analyze any given Python program for loops that are parallelizable.  First, it will perform array dependence analysis on the program to determine which loops are parallelizable -- possibly splitting the loops if some computations are dependence on other iterations while other computations are not.  We will get information about the analysis that was performed, which loops were parallelized and why, and how long the analysis took.  It will annotate the input Python source code with Cython if the loop is parallelizable.  These annotations will include both vector instrinsics and OpenMP.  Then, Cython will compile this output to a library binary, which can then be run and we can get speedup performance information from it.

  <h3> Hope to Achieve </h3>

  <p> In addition to the above, it would be cool to support multiple types of vector instrinsics and be platform independent.  Also, it would be great to compare multiple depedence testers to see how long each one takes, and to see how many loops and which loops each one identifies as parallelizable.  Ideally, it would be very cool to have my analysis combine the dependence testers in ways for ideal compile-time and loop parallelization checking. </p>

  <h3> Metrics </h3>

  <p> This project is mainly an analysis project, Once the analysis is over we have a bit of a systems project because we will be measuring performance of the annotated and vectorized loops that were deemed independent.  One performance metric will be measured by comparing the baseline with parallelized versions of the Python program.  This is important: the baseline is the valid <b> Python </b> program (i.e. not annotated with any Cython).  If the baseline is annoated with Cython's syntax, then it may be faster but not by means of this project.  We only want to be measuring the performance increased of adding the parallization to the loops.  We should be getting a 16x ideal speedup on our 2 way hyperthreaded 8 core CPU, but it will probably be closer to 8x (and even less if most of the program is not parallelizable loops). </p>

  <p> A more important metric to measure though for this project is a bit different than a performance though.  We should measure, in some way, how many loops were able to be determined to be independent.  It seems difficult to determine how many loops, and which loops I should be able to determine to be parallelizable.  I will ideally parallelize all loops that have independent iterations, but this will probably not be the case.  Also, it will be nice to have low analysis times.  I will be comparing analysis times with how many loops were able to be parallelized, which should be interesting.  This will all me to see the effectiveness of different dependence testers, including the one that is NP-hard (if the test can finish in a reasonable amount of time). </p>

  <h3> Demo </h3>
  
  <p> My demo will showing how my program automatically annotating a given Python program with the Cython superset and the resulting assembly compared with the baseline program.  It will also show which loops were able to be parallelized and why, and which loops were not able to be parallelized and why.  I will show that my program was able to automatically deduce that some loops were able to be parallizable and some loops were not able to be parallelizable.  It could be interactive!  Maybe I can have the class write a quick program together with a loop, then my program will analyze it and report speedups. </p>


<h1> Platform Choice </h1>

  <p> The 8 cores, two way hyperthreaded GHC machines should be good enough for interesting test results.  Python is a neat language to choose because it is so widely used.  The Cython compiler is needed in order to annotate the Python code with vector intrinsics and OpenMP.  Python's original implementation, CPython, just runs Python bytecode, which is slow and does not support vector instructions.  OpenMP provides an easy way to source-code-annotate a loop to be run in parallel. </p>

<h1> Schedule </h1>


Produce a schedule for your project. Your schedule should have at least one item to do per week. List what you plan to get done each week from now until the parallelism competition in order to meet your project goals. Keep in mind that due to other classes, you'll have more time to work some weeks than others (work that into the schedule). You will need to re-evaluate your progress at the end of each week and update this schedule accordingly. Note the intermediate checkpoint deadline is April 25th. In your schedule we encourage you to be precise as precise as possible. It's often helpful to work backward in time from your deliverables and goals, writing down all the little things you'll need to do (establish the dependencies!).

